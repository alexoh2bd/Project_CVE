
from pathlib import Path

import typer
import pandas as pd
import os
# import joblib
from config import (
    TRAIN_TEST_DIR,
    LOGGER,
)
from google.cloud import bigquery

from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from process_cve import process_cve_batches, merge_batch_results
app = typer.Typer()

os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "credentials.json"

# function generated by ChatGPT-5 on November 19, 2025
def clean_ml(df):
    # Convert datetime columns
    for col in ['published_date', 'last_modified_date']:
        if col in df:
            df[col] = pd.to_datetime(df[col], utc=True)     # ensure tz-aware UTC
            now = pd.Timestamp.now(tz="UTC")                # make now tz-aware
            df[col + '_age_days'] = (now - df[col]).dt.days


    # Target
    y = df['exploited'].astype(int)


    # Useful numeric cols
    numeric_cols = [
    'base_score','exploitability_score','impact_score',
    'published_date_age_days','last_modified_date_age_days'
    ]
    numeric_cols = [c for c in numeric_cols if c in df]


    # Useful categorical cols
    cat_cols = [
    'attack_vector','attack_complexity','privileges_required','user_interaction',
    'scope','confidentiality_impact','integrity_impact','availability_impact',
    'cwe_id','base_severity'
    ]
    cat_cols = [c for c in cat_cols if c in df]


    X = df[numeric_cols + cat_cols]


    # preprocessor
    numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ])


    categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore')),
    ])


    preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, cat_cols)
        ]
    )
    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y, random_state=42)
    return X_train, X_test, y_train,y_test, preprocessor

@app.command()
def main(
    output_path: Path = TRAIN_TEST_DIR,
):
    
    
    # Construct a BigQuery client object.
    client = bigquery.Client()

    # Define your SQL query
    query = """
        SELECT *
        FROM `ml-pipeline-lab-478617.cve.ML_features`
        
    """
    LOGGER.info(f"Querying...\n{query}")

    # Run the query as an api request
    query_job = client.query_and_wait(query)  
    df = query_job.to_dataframe()
    LOGGER.info(f"Query Complete! \n{df.head()}")
    

    X_train, X_test, y_train, y_test, preprocessor = clean_ml(df)

    X_train.to_csv(f"{output_path}/X_train.csv")
    X_test.to_csv(f"{output_path}/X_test.csv")
    y_train.to_csv(f"{output_path}/y_train.csv")
    y_test.to_csv(f"{output_path}/y_test.csv")
    # joblib.dump(preprocessor, f'{output_path}/column_transformer.joblib')


    

    

if __name__ == "__main__":
    app()
